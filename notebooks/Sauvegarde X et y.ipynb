{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46203005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "def csv_to_dataframes(output='ps'):\n",
    "    ''' Returns 2 dataframes\n",
    "\n",
    "    Extracts 1 dataframe with paragraphs and 1 dataframe with\n",
    "    sentences from a csv file. The csv files names' are parsed\n",
    "    assuming the following syntax:\n",
    "    \"author_name - title - publication_date.csv\"\n",
    "    '''\n",
    "    ##########################b#####################\n",
    "    ###y####  convert csv to df_paragraphs  ########\n",
    "    ################################################\n",
    "\n",
    "    # Get csv path ; the csv files are arrays of pre-selected* paragraphs\n",
    "    # that were extracted from raw txt files by * (cf. Lilou)\n",
    "    csv_path= \"/Users/cyrielle/code/Cyr-dcx/author_style/author_style/data/comp_aut\"\n",
    "\n",
    "\n",
    "    # Create a list of book names\n",
    "    books = [\n",
    "        csv_file for csv_file in os.listdir(csv_path)\n",
    "        if csv_file.endswith('.csv')]\n",
    "\n",
    "\n",
    "    # Parsing csv file names to get author names, book titles and publishing date\n",
    "    # and putting these elements in lists that have the same index as the list 'books'\n",
    "    authors = [csv_file.split(' ')[0]+' '+csv_file.split(' ')[1] for csv_file in books]\n",
    "    titles = [csv_file.split(' - ')[1] for csv_file in books]\n",
    "    book_dates = [csv_file.split(' - ')[2].replace('.csv','') for csv_file in books]\n",
    "\n",
    "    # Initializing a list of dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # For each book (in the list 'books'),\n",
    "    ## 1. create a dataframe with 1 paragraph per row\n",
    "    ## 2. create columns with fixed values for other features than text\n",
    "    ## 3. append the dataframe in the list 'dfs' of dataframes\n",
    "    ## containing the paragraphs from all books\n",
    "\n",
    "    for book in books:\n",
    "        ## 1.\n",
    "        df_temp = pd.read_csv(os.path.join(csv_path,book), header=None)\n",
    "        ## 2.\n",
    "        df_temp['author'] = authors[books.index(book)]\n",
    "        df_temp['title'] = titles[books.index(book)]\n",
    "        df_temp['book_date'] = book_dates[books.index(book)]\n",
    "        ## 3.\n",
    "        dfs.append(df_temp)\n",
    "\n",
    "    ## Concatenate all dataframes in 'dfs' to get\n",
    "    ## a single dataframe with paragraphs from all books\n",
    "    df_paragraphs = pd.concat([df for df in dfs], ignore_index = True, axis=0)\n",
    "    df_paragraphs.rename(mapper={0:\"text\"}, axis=1, inplace=True) # NB: The column name for the root_path text is explicitly called in a preprocessing function, it must be 'text'\n",
    "\n",
    "    ###############y########################################\n",
    "    ########  convert df_paragraphs to df_sentences  #######\n",
    "    #######################################b################\n",
    "\n",
    "    # Initializing a list of dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # For each paragraph of our dataset (i.e. for each row in df_paragraph):\n",
    "    for i in range(df_paragraphs['text'].count()):\n",
    "\n",
    "        # Separate sentences with '. ' as a delimiter\n",
    "        # (careful: \"J. C.\", \"Mr.\", [...]) ignore ?\n",
    "        sentences = str(df_paragraphs.text[i]).split(\". \")\n",
    "\n",
    "        # Prepare columns with fixed values for Author_name, Title and Book_date,\n",
    "        # to assign each sentence of a paragraph to the same Author_name, Title and Book_date.\n",
    "        author_temp = [df_paragraphs.author[i] for k in range(len(sentences))]\n",
    "        title_temp = [df_paragraphs.title[i] for k in range(len(sentences))]\n",
    "        date_temp = [df_paragraphs.book_date[i] for k in range(len(sentences))]\n",
    "\n",
    "        # Concatenate the 4 previous lists to build a single dataframe\n",
    "        # containing all sentences of the i-th paragraph of df_paragraphs\n",
    "        data = [sentences, author_temp, title_temp, date_temp]\n",
    "        df_temp = pd.DataFrame(data).T\n",
    "\n",
    "        # Build the list of dataframes containing all sentences of our dataset\n",
    "        dfs.append(df_temp)\n",
    "\n",
    "    # Assemble the dataframe containing all sentences of our dataset\n",
    "    df_sentences = pd.concat(dfs, ignore_index = True, axis=0)\n",
    "    df_sentences.rename(mapper={0:\"text\", 1: 'author', 2:'title', 3 : 'book_date'}, axis=1, inplace=True)\n",
    "\n",
    "    if output == 'p':\n",
    "        return df_paragraphs\n",
    "    if output == 's':\n",
    "        return df_sentences\n",
    "    if output == 'ps':\n",
    "        return df_paragraphs, df_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6babdf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "import unidecode\n",
    "#import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "\n",
    "def preprocess(text,\n",
    "               punctuation=False,\n",
    "               lower_case=True,\n",
    "               remove_stopwords=False,\n",
    "               accents=True,\n",
    "               numbers=True,\n",
    "               lemmatize=False,\n",
    "               language='french'):\n",
    "\n",
    "    if numbers:\n",
    "        text = ''.join(char for char in text if not char.isdigit())\n",
    "    if punctuation:\n",
    "        text = ''.join(char for char in text if not char in string.punctuation)\n",
    "    if lower_case:\n",
    "        text = text.lower()\n",
    "    if accents:\n",
    "        text = unidecode.unidecode(text)\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words(language))\n",
    "        word_tokens = word_tokenize(text)\n",
    "        text = ' '.join(char for char in word_tokens if not char in stop_words)\n",
    "    if lemmatize:\n",
    "        text = word_tokenize(text)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized = [lemmatizer.lemmatize(char) for char in text]\n",
    "        text = ' '.join(lemmatized)\n",
    "    return text\n",
    "\n",
    "\n",
    "def add_cleaned_column(df):\n",
    "    df[\"preprocess_data\"] = df['text'].apply(lambda x: preprocess(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"def return_token(sentence):\n",
    "    # Tokeniser la phrase\n",
    "    doc = nlp(sentence)\n",
    "    # Retourner le texte de chaque token\n",
    "    return [X.text for X in doc]\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"def return_word_embedding(sentence):\n",
    "    # Vectoriser la phrase\n",
    "    doc = nlp(sentence)\n",
    "    # Retourner le vecteur lié à chaque token\n",
    "    return [(X.vector) for X in doc]\"\"\"\n",
    "\n",
    "\n",
    "def stopword_count(text):\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stopword_count = len([w for w in word_tokens if w in stop_words])\n",
    "    return stopword_count\n",
    "\n",
    "\n",
    "def vocab_richness(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    if total_length > 0:\n",
    "        return unique_word_length / total_length\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def sentence_count(x):\n",
    "    if len(x.split()) >0:\n",
    "        return x.count('.') / len(x.split())\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def features(df, output='p'):\n",
    "    if output=='p':\n",
    "\n",
    "        df['preprocess_data'] = df['text'].apply(lambda x: preprocess(x))\n",
    "        df['word_ratio'] = df['text'].apply(lambda x: len(x.split()))\n",
    "        df['unique_word'] = df['text'].apply(\n",
    "        lambda x: 0 if len(x.split())==0 else (len(np.unique(x.split()))/ len(x.split())))\n",
    "\n",
    "        df['sentences_ratio'] = df['text'].apply(lambda x: 0 if len(x.split())==0 else x.count('.') / len(x.split()))\n",
    "        df['stopwords_ratio'] = df['text'].apply(lambda x: 0 if len(x.split(\n",
    "    )) == 0 else (stopword_count(x) / len(x.split())))\n",
    "        df['vocab richness'] = df['text'].apply(vocab_richness)\n",
    "        return df\n",
    "\n",
    "    elif output=='s':\n",
    "        df['preprocess_data'] = df['text'].apply(lambda x: preprocess(x))\n",
    "        df['word_ratio'] = df['text'].apply(lambda x: len(x.split()))\n",
    "        df['unique_word_ratio'] = df['text'].apply(\n",
    "        lambda x: 0 if len(x.split())==0 else (len(np.unique(x.split()))/ len(x.split())))\n",
    "\n",
    "        df['stopwords_ratio'] = df['text'].apply(lambda x: 0 if len(x.split(\n",
    "    )) == 0 else (stopword_count(x) / len(x.split())))\n",
    "        df['vocab richness'] = df['text'].apply(vocab_richness)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f1c0a",
   "metadata": {},
   "source": [
    "## Créer le dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4550d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv_to_dataframes(output=\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad559dc0",
   "metadata": {},
   "source": [
    "## Appliquer le preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3196af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = features(df, output='p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a6a4e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>book_date</th>\n",
       "      <th>preprocess_data</th>\n",
       "      <th>word_ratio</th>\n",
       "      <th>unique_word</th>\n",
       "      <th>sentences_ratio</th>\n",
       "      <th>stopwords_ratio</th>\n",
       "      <th>vocab richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pendant que Nous franchissions la porte du Nor...</td>\n",
       "      <td>GUTH Paul</td>\n",
       "      <td>Si j_étais le Bon Dieu</td>\n",
       "      <td>1987</td>\n",
       "      <td>pendant que nous franchissions la porte du nor...</td>\n",
       "      <td>235</td>\n",
       "      <td>0.672340</td>\n",
       "      <td>0.051064</td>\n",
       "      <td>0.463830</td>\n",
       "      <td>0.533557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>« En 486 après Jésus-Christ, les troupes de Sy...</td>\n",
       "      <td>GUTH Paul</td>\n",
       "      <td>Si j_étais le Bon Dieu</td>\n",
       "      <td>1987</td>\n",
       "      <td>&lt;&lt; en  apres jesus-christ, les troupes de syag...</td>\n",
       "      <td>261</td>\n",
       "      <td>0.685824</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.467433</td>\n",
       "      <td>0.546584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Van Eyck présenta La Vierge au chanoine Van de...</td>\n",
       "      <td>GUTH Paul</td>\n",
       "      <td>Si j_étais le Bon Dieu</td>\n",
       "      <td>1987</td>\n",
       "      <td>van eyck presenta la vierge au chanoine van de...</td>\n",
       "      <td>244</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.422131</td>\n",
       "      <td>0.537975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Un an après l’insolence du soldat, Clovis rass...</td>\n",
       "      <td>GUTH Paul</td>\n",
       "      <td>Si j_étais le Bon Dieu</td>\n",
       "      <td>1987</td>\n",
       "      <td>un an apres l'insolence du soldat, clovis rass...</td>\n",
       "      <td>218</td>\n",
       "      <td>0.848624</td>\n",
       "      <td>0.045872</td>\n",
       "      <td>0.284404</td>\n",
       "      <td>0.658451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Les hommes se font une idée grotesque du temps...</td>\n",
       "      <td>GUTH Paul</td>\n",
       "      <td>Si j_étais le Bon Dieu</td>\n",
       "      <td>1987</td>\n",
       "      <td>les hommes se font une idee grotesque du temps...</td>\n",
       "      <td>214</td>\n",
       "      <td>0.649533</td>\n",
       "      <td>0.051402</td>\n",
       "      <td>0.453271</td>\n",
       "      <td>0.533835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     author  \\\n",
       "0  Pendant que Nous franchissions la porte du Nor...  GUTH Paul   \n",
       "1  « En 486 après Jésus-Christ, les troupes de Sy...  GUTH Paul   \n",
       "2  Van Eyck présenta La Vierge au chanoine Van de...  GUTH Paul   \n",
       "3  Un an après l’insolence du soldat, Clovis rass...  GUTH Paul   \n",
       "4  Les hommes se font une idée grotesque du temps...  GUTH Paul   \n",
       "\n",
       "                     title book_date  \\\n",
       "0  Si j_étais le Bon Dieu      1987   \n",
       "1  Si j_étais le Bon Dieu      1987   \n",
       "2  Si j_étais le Bon Dieu      1987   \n",
       "3  Si j_étais le Bon Dieu      1987   \n",
       "4  Si j_étais le Bon Dieu      1987   \n",
       "\n",
       "                                     preprocess_data  word_ratio  unique_word  \\\n",
       "0  pendant que nous franchissions la porte du nor...         235     0.672340   \n",
       "1  << en  apres jesus-christ, les troupes de syag...         261     0.685824   \n",
       "2  van eyck presenta la vierge au chanoine van de...         244     0.688525   \n",
       "3  un an apres l'insolence du soldat, clovis rass...         218     0.848624   \n",
       "4  les hommes se font une idee grotesque du temps...         214     0.649533   \n",
       "\n",
       "   sentences_ratio  stopwords_ratio  vocab richness  \n",
       "0         0.051064         0.463830        0.533557  \n",
       "1         0.030651         0.467433        0.546584  \n",
       "2         0.049180         0.422131        0.537975  \n",
       "3         0.045872         0.284404        0.658451  \n",
       "4         0.051402         0.453271        0.533835  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c5d4b",
   "metadata": {},
   "source": [
    "## Créer X et y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1636762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection de X et y dans le dataframe df\n",
    "X = df[['preprocess_data']].to_numpy()\n",
    "y = df[\"author\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e95419be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"pendant que nous franchissions la porte du nord, dediee a ishtar, deesse de la fecondite, la vierge, toujours l'esprit en eveil, me donna une idee qui recut immediatement force de loi. pour compenser la fatigue que pourrait causer le jacassement universel, la derniere semaine de chaque mois serait vouee entierement au silence. un silence de reve suspendrait, sur la terre, le grondement des mers, le fracas des cascades, le souffle des vents, le vrombissement des avions, le bruit des trains, des voitures, des machines. il eteindrait, dans l'univers, la musique des spheres et tout fremissement de vie. cette semaine mensuelle de silence serait vouee a l'amour. en retenant leur souffle, les amoureux redoubleraient de regards, de caresses. ils ne seraient plus que rayonnements d'ame, scintillements d'indicible. quand ils retourneraient au monde de la parole, ils garderaient une telle nostalgie du silence qu'ils croiraient en dire infiniment moins avec leurs mots qu'auparavant avec leurs yeux. les plus nostalgiques seront les perroquets. et surtout kohkoh, perroquet en chef de nabuchodonosor, qui s'etait illustre en chantant des hymnes, des psaumes et les chefs-d'oeuvre de la poesie de babylone. apres chaque cure de silence, il etait si malheureux d'avoir a parler en service commande que, pour clore son bec a jamais, il finit par le plonger dans un ciment indestructible. pleure par le roi et par tout le royaume, il mourut d'amour du silence et du silence de l'amour.\"],\n",
       "       ['<< en  apres jesus-christ, les troupes de syagrius avaient enleve d\\'une eglise un vase d\\'une grandeur et d\\'une beaute merveilleuse, avec tous les autres ornements du ministere sacre. l\\'eveque de cette ville envoya au roi clovis des messagers demandant que, s\\'ils ne pouvaient obtenir de recouvrer les autres vases, on lui rendit au moins celui-la. aux paroles de l\\'envoye le roi repondit : \" suis-nous jusqu\\'a soissons car c est la que sera partage le butin ; et quand ce vase sera entre dans ma part, je ferai ce que l\\'eveque demande. \" en arrivant a soissons, le roi fit deposer la charge du butin au milieu de ses soldats et dit : \" je vous prie, mes braves guerriers, de bien vouloir m\\'accorder, hors part, le vase que voila \", et il montrait le vase dont nous avons parle. a ces paroles, les plus senses repondirent : \" glorieux roi, tout ce que nous avons ici est a toi, et nous-memes sommes soumis a ton pouvoir ; qu\\'il en soit donc fait selon ton jugement car personne ne peut resister a ta puissance. \" comme ils avaient ainsi parle, l\\'un des soldats, leger, jaloux et emporte, eleva la voix, brandit la hache a deux tranchants et frappa le vase en disant : \" tu n\\'auras rien de plus que ce qui te sera donne veritablement par le sort. \" tous resterent stupefaits. le roi comprima l\\'outrage, avec une patiente douceur, et le vase lui etant echu, il le rendit a l\\'envoye de l\\'eveque, gardant la blessure dans son coeur.'],\n",
       "       [\"van eyck presenta la vierge au chanoine van der paele, avec le chanoine lui-meme, la vierge a la fontaine et, avec le chancelier en personne, << gros et gras, le teint frais et la bouche vermeille >>, la vierge au chancelier rolin. pour mieux contempler ce chef-d'oeuvre, je fis arreter le cortege. serenite de la vierge peinte dans son grand manteau rouge. ce regard en biais, attentif, de sage et discrete personne, empechant, du bout des doigts, l'enfant de glisser sur son genou et s'appretant a lui donner l'envol. les magiques cheveux d'or crespeles cascadant sur les epaules. au-dessus de sa tete, un ange eleve une couronne a faire palir d'envie saint eloi. un immense joyau arachneen, une dentelle d'or, un souffle de filigranes, royaute des cieux. et puis le coup de genie, que j'ai inspire, auquel van eyck a obei, autant que le permettaient ses forces : la vierge a l'enfant est assise dans la penombre d'une loggia, a l'angle de laquelle l'ange se niche comme une hirondelle. des arceaux s'ouvrent sur un ciel ideal. en bas, apparait une de ces villes de reve dont le petit paul guth, au musee de toulouse, pendant la grande guerre, nourrissait a jamais ses songes. assise au bord d'un fleuve, une cite, herissee de fleches et de tours, ciselee, orfevree comme la couronne de la vierge. une de ces villes ou l'on voudrait vivre, dans la realisation de tous les voeux, sous un ciel sans bornes.\"],\n",
       "       ...,\n",
       "       [\"reste la possibilite d'aller faire un tour dans le jardin qui est un espace a trois cotes, herbu, pentu, bombe comme un triangle de fille. mais ce jardin, ce jour-la, ravel a beau s'y tenir d'habitude attentif, c'est a peine a present s'il le voit, a peine s'il s'interesse aux travaux effectues en son absence par le jardinier. on dirait qu'il commence a s'ennuyer.\"],\n",
       "       [\"le lendemain matin, il se leve tard, trainant au lit jusqu'a rater le bouillon sur le pont puis, vetu de coton gaufre decontracte, il va faire un tour sur le pont promenade a peu pres desert : deux mousses y regroupent sur des plateaux des bols epars entre les pieds des chaises longues, la mer est d'un vert presque noir.\"],\n",
       "       [\"il part en direction de la gare maritime du havre afin de se rendre en amerique du nord. c'est la premiere fois qu'il y va, ce sera la derniere. il lui reste aujourd'hui, pile, dix ans a vivre.\"]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a219c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Label Encode y\n",
    "cat_transformer = LabelEncoder()\n",
    "y = cat_transformer.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbc8c6",
   "metadata": {},
   "source": [
    "## Sauvegarder X et y sur le package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e90d2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(X,\"X.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "645c3d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y,\"y.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437f066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
